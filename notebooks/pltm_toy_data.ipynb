{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "016b5f77-6a30-455a-afbb-97776352c207",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "np.set_printoptions(threshold=100, linewidth=200)\n",
    "\n",
    "from scipy.stats import multinomial\n",
    "\n",
    "from pprint import pprint\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a8a2c4c5-0792-4989-ae7c-28fb8a877f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "D = 100  # 文書数\n",
    "V = 10   # 語彙数\n",
    "S = 5    # 補助情報の異なり数\n",
    "\n",
    "true_K = 3 # トピック数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1e4db7fb-1a16-46e1-be4a-7310a95cf2be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "真の文書トピック分布 (D, K):\n",
      "array([[0.47715612, 0.42480248, 0.0980414 ],\n",
      "       [0.3645711 , 0.00516574, 0.63026316],\n",
      "       [0.31790992, 0.43482774, 0.24726234],\n",
      "       ...,\n",
      "       [0.06231124, 0.91405667, 0.02363209],\n",
      "       [0.15043133, 0.77092695, 0.07864172],\n",
      "       [0.66226774, 0.14294696, 0.19478531]])\n"
     ]
    }
   ],
   "source": [
    "# トピック分布のハイパーパラメータを設定\n",
    "true_alpha = 1\n",
    "true_alpha_k = [true_alpha] * true_K\n",
    "\n",
    "# トピック分布のパラメータを生成\n",
    "true_theta_dk = np.random.dirichlet(alpha=true_alpha_k, size=D)\n",
    "\n",
    "print(\"真の文書トピック分布 (D, K):\")\n",
    "pprint(true_theta_dk)\n",
    "\n",
    "assert np.all(np.abs(true_theta_dk.sum(axis=1) - 1.0) < 1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dde31725-5284-49e5-87e6-23075277d8b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "真のトピック単語分布 (K, V):\n",
      "array([[0.14145115, 0.05127865, 0.13721486, 0.13788182, 0.01108607, 0.12030375, 0.10666786, 0.20661903, 0.06181732, 0.02567949],\n",
      "       [0.3146547 , 0.04197229, 0.01122971, 0.00996433, 0.1000627 , 0.02793935, 0.10836364, 0.09118042, 0.03683826, 0.2577946 ],\n",
      "       [0.00698908, 0.0906779 , 0.00425406, 0.00746471, 0.07192889, 0.08294173, 0.21488317, 0.00440974, 0.17474627, 0.34170444]])\n"
     ]
    }
   ],
   "source": [
    "# 単語分布のハイパーパラメータを設定\n",
    "true_beta_v = 1\n",
    "true_beta_v = [true_beta_v] * V\n",
    "\n",
    "# 単語分布のパラメータを生成\n",
    "true_phi_kv = np.random.dirichlet(alpha=true_beta_v, size=true_K)\n",
    "\n",
    "print(\"真のトピック単語分布 (K, V):\")\n",
    "pprint(true_phi_kv)\n",
    "\n",
    "assert np.all(np.abs(true_phi_kv.sum(axis=1) - 1.0) < 1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5a27cbd5-9217-4fd8-a1b5-9388389a9d6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "真の補助情報分布 (K, S):\n",
      "array([[0.38020759, 0.15234791, 0.00928943, 0.18295682, 0.27519825],\n",
      "       [0.16808777, 0.56906787, 0.0596455 , 0.10941344, 0.09378542],\n",
      "       [0.09469105, 0.07640532, 0.05935909, 0.07722108, 0.69232346]])\n"
     ]
    }
   ],
   "source": [
    "# 補助情報分布のハイパーパラメータ\n",
    "true_beta_s = 1\n",
    "true_beta_s = [true_beta_s] * S\n",
    "\n",
    "# 補助情報分布のパラメータを生成\n",
    "true_phi_ks = np.random.dirichlet(alpha=true_beta_s, size=true_K)\n",
    "\n",
    "print(\"真の補助情報分布 (K, S):\")\n",
    "pprint(true_phi_ks)\n",
    "\n",
    "assert np.all(np.abs(true_phi_ks.sum(axis=1) - 1.0) < 1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eaee7bc1-4de4-4f77-a714-a9497cef981c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [00:00<00:00, 539.01it/s]\n"
     ]
    }
   ],
   "source": [
    "## テスト文書を生成\n",
    "\n",
    "W = [] # 文書集合を初期化\n",
    "Z = [] # トピック集合を初期化\n",
    "\n",
    "X = [] # 補助情報集合を初期化\n",
    "Y = [] # 補助情報トピック集合を初期化\n",
    "\n",
    "N_d = [None] * D        # 各文書の単語数を初期化\n",
    "N_dw = np.zeros((D, V)) # 文書ごとの各語彙の出現頻度を初期化\n",
    "\n",
    "M_d = [None] * D        # 各文書の補助情報数を初期化\n",
    "M_dx = np.zeros((D, S)) # 文書ごとの各補助情報の出現頻度を初期化\n",
    "\n",
    "min_N_d = 100 # 各文書の単語数の上限\n",
    "max_N_d = 200 # 各文書の単語数の下限\n",
    "\n",
    "min_M_d = 5  # 各文書の単語数の上限\n",
    "max_M_d = 10 # 各文書の単語数の下限\n",
    "\n",
    "for d in tqdm(range(D)):\n",
    "    # 単語数を生成\n",
    "    N_d[d] = np.random.randint(low=min_N_d, high=max_N_d)\n",
    "    # 各単語のトピックを初期化\n",
    "    true_z_dn = [None] * N_d[d]\n",
    "    # 各単語の語彙を初期化\n",
    "    w_dn = [None] * N_d[d]\n",
    "\n",
    "    # 補助情報数を生成\n",
    "    M_d[d] = np.random.randint(low=min_M_d, high=max_M_d)\n",
    "    # 各補助情報のトピックを初期化\n",
    "    true_y_dn = [None] * M_d[d]\n",
    "    # 各補助情報を初期化\n",
    "    x_dn = [None] * M_d[d]\n",
    "\n",
    "    for n in range(N_d[d]):\n",
    "        # トピックを生成\n",
    "        z = np.random.choice(true_K, p=true_theta_dk[d])\n",
    "        true_z_dn[n] = z\n",
    "        # 語彙を生成\n",
    "        w = np.random.choice(V, p=true_phi_kv[z])\n",
    "        w_dn[n] = w\n",
    "        # 単語頻度をカウント\n",
    "        N_dw[d, w] += 1\n",
    "\n",
    "    for m in range(M_d[d]):\n",
    "        # 補助情報トピックを生成\n",
    "        y = np.random.choice(true_K, p=true_theta_dk[d])\n",
    "        true_y_dn[m] = y\n",
    "        # 補助情報を生成\n",
    "        x = np.random.choice(S, p=true_phi_ks[y])\n",
    "        x_dn[m] = x\n",
    "        # 補助情報頻度をカウント\n",
    "        M_dx[d, x] += 1\n",
    "\n",
    "    # トピック集合を格納\n",
    "    Z.append(true_z_dn)\n",
    "    # 単語集合を格納\n",
    "    W.append(w_dn)\n",
    "    # 補助情報トピック集合を格納\n",
    "    Y.append(true_y_dn)\n",
    "    # 補助情報集合を格納\n",
    "    X.append(x_dn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fc31b449-6c4d-419f-b76f-5c2bd40acecb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 5 0 9 1 3 0 5 7 0 7 3 6 2 5 0 5 3 4 0 2 6 5 9 1 4 1 2 4 0 5 0 7 0 1 5 0 7 3 6 0 3 4 0 0 2 4 7 0 3 7 4 0 6 5 6 0 7 7 7 5 3 7 7 9 6 2 9 3 6 9 8 9 0 8 0 9 9 0 6 6 3 7 0 0 7 6 8 8 0 8 1 2 9 6 9 0 1 4 6 9 0 8 0 6 3 0 5 6 9 9 5 6 0 0 3 0 0 7 0 7 4 9 7 1 0 7 9 6 0 7 9 7 8 5 3 2 5 9 0 0 2 3 7 1 3 9 0 2 5 0 6 8 4 5 0 9 7 7 8 5 7 0 4 5 1 5 9 0 7 0 5 9 9 6 0 9 9 0 3 0 6 6 1 5 9 7 0 0 2 0 7 7 7 9 8\n",
      "0 2 1 6 3 6 6 5 1 2 6 6 8 6 8 4 3 8 6 6 6 8 9 5 9 9 7 2 7 7 9 4 8 9 3 0 9 6 1 9 9 7 9 0 6 9 9 2 9 3 4 8 9 6 9 6 1 9 8 7 6 7 6 1 8 0 9 3 5 6 9 5 6 3 6 4 5 5 4 9 9 6 8 7 9 7 1 4 9 9 9 1 8 8 7 6 9 8 1 1 4 9 1 9 2 9 4 3 6 9 3 6 8 6 8 5 6 9 2 6 9 5 0 6 9 5 7 8 2 9 5 8 9 8 4 6 5 1 9 1 9 9 1 4 5 5 2 3 8 8 9 1 9 3 6 5 6 6 8 6 7 8 6 0 8 5 6 4 4 9 9 8 9 3 9 7 3\n"
     ]
    }
   ],
   "source": [
    "# テスト文書をファイルに出力\n",
    "with open(\"pltm.test.txt\", mode=\"w\") as f:\n",
    "    print(\"\\n\".join([\" \".join([str(w) for w in words]) for words in W]), file=f)\n",
    "\n",
    "!head -n2 pltm.test.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "98319eaf-e4c6-41be-993b-87a743b8dc70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 4 4 3 0 1 3\n",
      "4 4 4 4 0 1\n"
     ]
    }
   ],
   "source": [
    "# テスト補助情報をファイルに出力\n",
    "with open(\"pltm.test.x.txt\", mode=\"w\") as f:\n",
    "    print(\"\\n\".join([\" \".join([str(x) for x in xs]) for xs in X]), file=f)\n",
    "\n",
    "!head -n2 pltm.test.x.txt"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
